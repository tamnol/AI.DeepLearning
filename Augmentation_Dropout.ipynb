{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Augmentation_Dropout.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamnol/DeepLearning-AI/blob/master/Augmentation_Dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "f3ab5169-af75-4301-a05d-72be4422b46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3( input_shape= (150,150,3),\n",
        "                                include_top= False,\n",
        "                                weights= None\n",
        "                               )\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-28 02:30:22--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   230MB/s    in 0.4s    \n",
            "\n",
            "2019-07-28 02:30:23 (230 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0728 02:30:23.634533 139933967185792 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "b92e1a4a-66b6-4162-d33c-8c0b7d225ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "59b2234c-cb40-40bf-9dc8-5c050dba4338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation= tf.nn.relu)(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation= tf.nn.sigmoid)(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss =  'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0728 02:30:57.102906 139933967185792 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "48bf26a0-b829-4dd7-b350-d62b0f421b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "with open(local_zip, 'r') as file_train:\n",
        "  zip_ref = zipfile.ZipFile(file_train)\n",
        "  zip_ref.extractall('/tmp/training')\n",
        "  print('the pointer for training is at {} bytes number'.format(file_train.tell()))\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "with open(local_zip, 'r') as file_valid:\n",
        "  zip_ref = zipfile.ZipFile(file_valid)\n",
        "  zip_ref.extractall('/tmp/validation')\n",
        "  print('the pointer for validation is at {} bytes number'.format(file_valid.tell()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-28 02:31:29--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   141MB/s    in 1.0s    \n",
            "\n",
            "2019-07-28 02:31:30 (141 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-07-28 02:31:32--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-07-28 02:31:32 (94.6 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n",
            "the pointer for training is at 149506536 bytes number\n",
            "the pointer for validation is at 11462629 bytes number\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "012251ba-f482-4bf2-b31e-dcea8e062e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_horses_dir = os.path.join('/tmp/training/', 'horses')\n",
        "train_humans_dir = os.path.join('/tmp/training/', 'humans')\n",
        "validation_horses_dir = os.path.join('/tmp/validation/', 'horses')\n",
        "validation_humans_dir = os.path.join('/tmp/validation/', 'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print('Number of training horses: {}'.format(len(train_horses_fnames)))\n",
        "print('Number of training humans: {}'.format(len(train_humans_fnames)))\n",
        "print('Number of validation horses: {}'.format(len(validation_horses_fnames)))\n",
        "print('Number of validation humans: {}'.format(len(validation_humans_fnames)))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training horses: 500\n",
            "Number of training humans: 527\n",
            "Number of validation horses: 128\n",
            "Number of validation humans: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "03fd9109-ee4b-49d3-8847-a32475d51cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "                                   rescale = 1./255.,\n",
        "                                   featurewise_center=True,\n",
        "                                   featurewise_std_normalization=True,\n",
        "                                   rotation_range = 90,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1./255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   batch_size = 11,\n",
        "                                                   class_mode ='binary',\n",
        "                                                   target_size= (150,150) )     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                   batch_size = 11,\n",
        "                                                   class_mode ='binary',\n",
        "                                                   target_size= (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "861ed4da-572e-4bd4-fbf9-fdacb59f6850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator( \n",
        "                              train_generator,\n",
        "                              validation_data = validation_generator,\n",
        "                              steps_per_epoch = 100,\n",
        "                              epochs = 80,\n",
        "                              validation_steps = 23,\n",
        "                              callbacks = [callbacks],\n",
        "                                  verbose =2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "100/100 - 14s - loss: 0.1162 - acc: 0.9707 - val_loss: 0.3668 - val_acc: 0.9684\n",
            "Epoch 2/80\n",
            "100/100 - 13s - loss: 0.0798 - acc: 0.9744 - val_loss: 0.0772 - val_acc: 0.9842\n",
            "Epoch 3/80\n",
            "100/100 - 13s - loss: 0.0528 - acc: 0.9835 - val_loss: 0.2020 - val_acc: 0.9763\n",
            "Epoch 4/80\n",
            "100/100 - 13s - loss: 0.0589 - acc: 0.9817 - val_loss: 0.1809 - val_acc: 0.9802\n",
            "Epoch 5/80\n",
            "100/100 - 13s - loss: 0.0556 - acc: 0.9817 - val_loss: 0.2495 - val_acc: 0.9723\n",
            "Epoch 6/80\n",
            "100/100 - 13s - loss: 0.0848 - acc: 0.9835 - val_loss: 0.1676 - val_acc: 0.9763\n",
            "Epoch 7/80\n",
            "100/100 - 13s - loss: 0.0657 - acc: 0.9790 - val_loss: 0.0523 - val_acc: 0.9960\n",
            "Epoch 8/80\n",
            "100/100 - 13s - loss: 0.0644 - acc: 0.9862 - val_loss: 0.0893 - val_acc: 0.9842\n",
            "Epoch 9/80\n",
            "100/100 - 13s - loss: 0.0678 - acc: 0.9808 - val_loss: 0.2718 - val_acc: 0.9723\n",
            "Epoch 10/80\n",
            "100/100 - 13s - loss: 0.0758 - acc: 0.9762 - val_loss: 0.0144 - val_acc: 0.9960\n",
            "Epoch 11/80\n",
            "100/100 - 13s - loss: 0.1158 - acc: 0.9771 - val_loss: 0.0520 - val_acc: 0.9842\n",
            "Epoch 12/80\n",
            "100/100 - 13s - loss: 0.0792 - acc: 0.9744 - val_loss: 0.4793 - val_acc: 0.9644\n",
            "Epoch 13/80\n",
            "100/100 - 13s - loss: 0.0699 - acc: 0.9780 - val_loss: 0.4797 - val_acc: 0.9644\n",
            "Epoch 14/80\n",
            "100/100 - 13s - loss: 0.0739 - acc: 0.9826 - val_loss: 0.3814 - val_acc: 0.9644\n",
            "Epoch 15/80\n",
            "100/100 - 12s - loss: 0.0484 - acc: 0.9854 - val_loss: 0.1549 - val_acc: 0.9802\n",
            "Epoch 16/80\n",
            "100/100 - 13s - loss: 0.0984 - acc: 0.9808 - val_loss: 0.4799 - val_acc: 0.9644\n",
            "Epoch 17/80\n",
            "100/100 - 13s - loss: 0.0578 - acc: 0.9799 - val_loss: 0.4864 - val_acc: 0.9644\n",
            "Epoch 18/80\n",
            "100/100 - 13s - loss: 0.0539 - acc: 0.9844 - val_loss: 0.4881 - val_acc: 0.9644\n",
            "Epoch 19/80\n",
            "100/100 - 13s - loss: 0.0753 - acc: 0.9808 - val_loss: 0.4394 - val_acc: 0.9644\n",
            "Epoch 20/80\n",
            "100/100 - 13s - loss: 0.0654 - acc: 0.9835 - val_loss: 0.4429 - val_acc: 0.9644\n",
            "Epoch 21/80\n",
            "100/100 - 13s - loss: 0.0411 - acc: 0.9899 - val_loss: 0.3657 - val_acc: 0.9723\n",
            "Epoch 22/80\n",
            "100/100 - 12s - loss: 0.0562 - acc: 0.9872 - val_loss: 0.0072 - val_acc: 0.9960\n",
            "Epoch 23/80\n",
            "100/100 - 12s - loss: 0.0832 - acc: 0.9816 - val_loss: 0.5661 - val_acc: 0.9644\n",
            "Epoch 24/80\n",
            "100/100 - 12s - loss: 0.0436 - acc: 0.9872 - val_loss: 0.4636 - val_acc: 0.9644\n",
            "Epoch 25/80\n",
            "100/100 - 13s - loss: 0.0603 - acc: 0.9818 - val_loss: 0.3794 - val_acc: 0.9644\n",
            "Epoch 26/80\n",
            "100/100 - 12s - loss: 0.0309 - acc: 0.9899 - val_loss: 0.6065 - val_acc: 0.9644\n",
            "Epoch 27/80\n",
            "100/100 - 12s - loss: 0.0412 - acc: 0.9890 - val_loss: 0.1663 - val_acc: 0.9723\n",
            "Epoch 28/80\n",
            "100/100 - 12s - loss: 0.0172 - acc: 0.9945 - val_loss: 0.3641 - val_acc: 0.9684\n",
            "Epoch 29/80\n",
            "100/100 - 12s - loss: 0.0411 - acc: 0.9890 - val_loss: 0.4061 - val_acc: 0.9684\n",
            "Epoch 30/80\n",
            "100/100 - 13s - loss: 0.0759 - acc: 0.9873 - val_loss: 0.2542 - val_acc: 0.9763\n",
            "Epoch 31/80\n",
            "100/100 - 12s - loss: 0.0432 - acc: 0.9843 - val_loss: 0.5108 - val_acc: 0.9644\n",
            "Epoch 32/80\n",
            "100/100 - 13s - loss: 0.0553 - acc: 0.9863 - val_loss: 0.7988 - val_acc: 0.9565\n",
            "Epoch 33/80\n",
            "100/100 - 13s - loss: 0.0477 - acc: 0.9909 - val_loss: 0.6112 - val_acc: 0.9644\n",
            "Epoch 34/80\n",
            "100/100 - 12s - loss: 0.0304 - acc: 0.9917 - val_loss: 0.3688 - val_acc: 0.9684\n",
            "Epoch 35/80\n",
            "100/100 - 13s - loss: 0.0623 - acc: 0.9873 - val_loss: 0.3375 - val_acc: 0.9684\n",
            "Epoch 36/80\n",
            "100/100 - 12s - loss: 0.0487 - acc: 0.9844 - val_loss: 0.3686 - val_acc: 0.9684\n",
            "Epoch 37/80\n",
            "100/100 - 13s - loss: 0.0583 - acc: 0.9853 - val_loss: 0.5305 - val_acc: 0.9644\n",
            "Epoch 38/80\n",
            "100/100 - 13s - loss: 0.0292 - acc: 0.9918 - val_loss: 0.4820 - val_acc: 0.9644\n",
            "Epoch 39/80\n",
            "100/100 - 12s - loss: 0.0326 - acc: 0.9891 - val_loss: 0.7154 - val_acc: 0.9565\n",
            "Epoch 40/80\n",
            "100/100 - 12s - loss: 0.0492 - acc: 0.9880 - val_loss: 0.2962 - val_acc: 0.9723\n",
            "Epoch 41/80\n",
            "100/100 - 13s - loss: 0.0289 - acc: 0.9891 - val_loss: 0.2391 - val_acc: 0.9723\n",
            "Epoch 42/80\n",
            "100/100 - 13s - loss: 0.0268 - acc: 0.9899 - val_loss: 0.4522 - val_acc: 0.9684\n",
            "Epoch 43/80\n",
            "100/100 - 12s - loss: 0.0424 - acc: 0.9891 - val_loss: 0.7418 - val_acc: 0.9605\n",
            "Epoch 44/80\n",
            "100/100 - 13s - loss: 0.0921 - acc: 0.9807 - val_loss: 0.3275 - val_acc: 0.9723\n",
            "Epoch 45/80\n",
            "100/100 - 12s - loss: 0.0400 - acc: 0.9881 - val_loss: 0.3448 - val_acc: 0.9684\n",
            "Epoch 46/80\n",
            "100/100 - 12s - loss: 0.0597 - acc: 0.9790 - val_loss: 0.6923 - val_acc: 0.9565\n",
            "Epoch 47/80\n",
            "100/100 - 13s - loss: 0.0457 - acc: 0.9872 - val_loss: 0.4472 - val_acc: 0.9684\n",
            "Epoch 48/80\n",
            "100/100 - 13s - loss: 0.0527 - acc: 0.9844 - val_loss: 0.5388 - val_acc: 0.9644\n",
            "Epoch 49/80\n",
            "100/100 - 13s - loss: 0.0373 - acc: 0.9899 - val_loss: 0.6626 - val_acc: 0.9644\n",
            "Epoch 50/80\n",
            "100/100 - 12s - loss: 0.0548 - acc: 0.9863 - val_loss: 0.4838 - val_acc: 0.9644\n",
            "Epoch 51/80\n",
            "100/100 - 12s - loss: 0.0640 - acc: 0.9826 - val_loss: 0.5473 - val_acc: 0.9644\n",
            "Epoch 52/80\n",
            "100/100 - 12s - loss: 0.0627 - acc: 0.9890 - val_loss: 0.7259 - val_acc: 0.9644\n",
            "Epoch 53/80\n",
            "100/100 - 13s - loss: 0.0396 - acc: 0.9890 - val_loss: 0.7077 - val_acc: 0.9644\n",
            "Epoch 54/80\n",
            "100/100 - 12s - loss: 0.0356 - acc: 0.9909 - val_loss: 0.5866 - val_acc: 0.9644\n",
            "Epoch 55/80\n",
            "100/100 - 12s - loss: 0.0383 - acc: 0.9881 - val_loss: 0.6420 - val_acc: 0.9644\n",
            "Epoch 56/80\n",
            "100/100 - 12s - loss: 0.0757 - acc: 0.9881 - val_loss: 0.6708 - val_acc: 0.9644\n",
            "Epoch 57/80\n",
            "100/100 - 12s - loss: 0.0473 - acc: 0.9871 - val_loss: 0.5857 - val_acc: 0.9644\n",
            "Epoch 58/80\n",
            "100/100 - 12s - loss: 0.0240 - acc: 0.9936 - val_loss: 0.2449 - val_acc: 0.9723\n",
            "Epoch 59/80\n",
            "100/100 - 12s - loss: 0.0409 - acc: 0.9890 - val_loss: 0.3444 - val_acc: 0.9723\n",
            "Epoch 60/80\n",
            "100/100 - 13s - loss: 0.0330 - acc: 0.9909 - val_loss: 0.6140 - val_acc: 0.9644\n",
            "Epoch 61/80\n",
            "100/100 - 12s - loss: 0.0161 - acc: 0.9936 - val_loss: 0.2201 - val_acc: 0.9802\n",
            "Epoch 62/80\n",
            "100/100 - 12s - loss: 0.0483 - acc: 0.9872 - val_loss: 0.4334 - val_acc: 0.9644\n",
            "Epoch 63/80\n",
            "100/100 - 13s - loss: 0.0331 - acc: 0.9881 - val_loss: 0.0482 - val_acc: 0.9960\n",
            "Epoch 64/80\n",
            "100/100 - 12s - loss: 0.0524 - acc: 0.9890 - val_loss: 0.3428 - val_acc: 0.9723\n",
            "Epoch 65/80\n",
            "100/100 - 12s - loss: 0.0513 - acc: 0.9871 - val_loss: 0.6201 - val_acc: 0.9644\n",
            "Epoch 66/80\n",
            "100/100 - 12s - loss: 0.0677 - acc: 0.9882 - val_loss: 0.6435 - val_acc: 0.9644\n",
            "Epoch 67/80\n",
            "100/100 - 12s - loss: 0.0330 - acc: 0.9890 - val_loss: 0.9874 - val_acc: 0.9526\n",
            "Epoch 68/80\n",
            "100/100 - 13s - loss: 0.0167 - acc: 0.9963 - val_loss: 0.7402 - val_acc: 0.9644\n",
            "Epoch 69/80\n",
            "100/100 - 12s - loss: 0.0083 - acc: 0.9963 - val_loss: 0.8303 - val_acc: 0.9605\n",
            "Epoch 70/80\n",
            "100/100 - 13s - loss: 0.0292 - acc: 0.9945 - val_loss: 0.2839 - val_acc: 0.9723\n",
            "Epoch 71/80\n",
            "100/100 - 12s - loss: 0.0529 - acc: 0.9890 - val_loss: 0.4843 - val_acc: 0.9684\n",
            "Epoch 72/80\n",
            "100/100 - 13s - loss: 0.0439 - acc: 0.9900 - val_loss: 0.4825 - val_acc: 0.9723\n",
            "Epoch 73/80\n",
            "100/100 - 12s - loss: 0.0578 - acc: 0.9899 - val_loss: 0.6517 - val_acc: 0.9644\n",
            "Epoch 74/80\n",
            "100/100 - 12s - loss: 0.0552 - acc: 0.9881 - val_loss: 0.9315 - val_acc: 0.9565\n",
            "Epoch 75/80\n",
            "100/100 - 12s - loss: 0.0706 - acc: 0.9890 - val_loss: 0.9717 - val_acc: 0.9486\n",
            "Epoch 76/80\n",
            "100/100 - 13s - loss: 0.0372 - acc: 0.9882 - val_loss: 0.8913 - val_acc: 0.9526\n",
            "Epoch 77/80\n",
            "100/100 - 12s - loss: 0.0297 - acc: 0.9899 - val_loss: 1.0043 - val_acc: 0.9486\n",
            "Epoch 78/80\n",
            "100/100 - 12s - loss: 0.0364 - acc: 0.9927 - val_loss: 1.3101 - val_acc: 0.9447\n",
            "Epoch 79/80\n",
            "100/100 - 13s - loss: 0.0631 - acc: 0.9835 - val_loss: 0.8732 - val_acc: 0.9526\n",
            "Epoch 80/80\n",
            "100/100 - 12s - loss: 0.0166 - acc: 0.9954 - val_loss: 0.9659 - val_acc: 0.9486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "665037c6-faa5-458e-ae40-84c1007577c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}